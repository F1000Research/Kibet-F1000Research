{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Walk through all steps used in research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, lets import all the base modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import errno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Convert the ENCODE data into posneg format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "posneg format is a format we jsut made up to represent a file in the following format: \n",
    "\n",
    "    chromosome:start-end score sequence eg\n",
    "\n",
    "    chr19:10828427-10828527\t486.128011369018 TCTACTGGCACGTCTGCCTGCCAATAAGAT\n",
    "    \n",
    "To convert to this format, the following are required:\n",
    "\n",
    "1. A human genome file in Hg19 format that has been repeat-masked with NNs\n",
    "2. MEME fastafrombed script--jsut get compete meme tools, you'll need them later\n",
    "+ A bedwidden scrpt from the folowing site.\n",
    "\n",
    "A script to execute the whole process is provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Encode to bed file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cut -f1,2,3,7 wgEncodeAwgTfbsBroadDnd41CtcfUniPk.narrowPeak >BroadDnd41Ctcf-tmp.bed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Extract the fasta files in the posneg format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genome_path = 'provide path to hg19'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system(\"./bed2chipseg.sh ./BroadDnd41Ctcf-tmp.bed  BroadDnd41Ctcf %s\" %genome_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming the motifs have been generated, they can be used to score the above sequences using the following scoring functions:\n",
    "\n",
    "    1. gomeroccupnacyscore\n",
    "    2. energyscore\n",
    "    3. maxoccupancyscore\n",
    "    4. occupancyscore\n",
    "    5. occupancyscore\n",
    "    6. sumlogoddsscore\n",
    "    7. maxlogoddsscore\n",
    "In my case, I querried a local motf database for motifs for a given TF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Import the module to directly access the functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import Assess_motifsdb as assess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Get the base directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath('Assess_motifsdb.py')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of this demo, we are going to use Ctcf motifs.\n",
    "\n",
    "Create a results directory complete with paths using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mkdir_p(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exc:\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
    "            pass\n",
    "        else:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf = 'ctcf'\n",
    "results_path = '%s/Results/%s' % (BASE_DIR, tf)\n",
    "mkdir_p(results_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the Results folder for Ctcf in place, the next this in to get a list of all the ChIP-seq data convered as shown above to posneg format. We use the function below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "chip_seq_list = glob.glob('%s/Data/Derived/%s/*' % (BASE_DIR, tf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use gomeroccupancy score for this demo, but a quick run for all the motifs can be run by looping though all the scoring functions as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for key in assess.score_extensions:\n",
    "    #assess.run_all(tf, key, '%s/Data/Motifs/%s.meme' %(BASE_DIR, tf), chip_seq_list, results_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the above cell for a quick run of all the scoring functions. Internally, the program chooses 10 random sequences, in a situation where more than 10 are available. We observed no better discrimination from more data, just takes lots of time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "key = 'gomeroccupancyscore'\n",
    "assess.run_all(tf, key, '%s/Data/Motifs/%s.meme' %(BASE_DIR, tf), chip_seq_list, results_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Combining the above steps to loop through multiple TFs and scoring functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tf_list = \"cebpb ctcf egr1 elf1 esrra ets1 gata3 hnf4a mafk max mef2a myb nrf1 pax5 pou2f2 prdm1 sp1 srf tcf3 yy1\".split()\n",
    "tf_list = ['ctcf']\n",
    "for tf in tf_list:\n",
    "    results_path = '%s/Results/%s' % (BASE_DIR, tf)\n",
    "    \n",
    "    #make results path\n",
    "    mkdir_p(results_path)\n",
    "    \n",
    "    #Exract the available ChIP-seq list\n",
    "    chip_seq_list = glob.glob('%s/Data/Derived/%s/*' % (BASE_DIR, tf))\n",
    "    \n",
    "    test_meme_input = '%s/Data/Motifs/%s.meme' %(BASE_DIR, tf)\n",
    "    \n",
    "    for key in assess.score_extensions:\n",
    "        assess.run_all(tf, key, test_meme_input, chip_seq_list, results_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##Run analysis using CentriMo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For motif enrichment analsys, a *run_centrimo* module is provided. This requires that the The MEME Suite tools version 4.10.0, which can be intsalled from <a href='http://meme-suite.org/doc/download.html?man_type=web'>MEME-Suite</a>.\n",
    "\n",
    "The steps followed are similar as above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import run_centrimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tf_list = \"cebpb ctcf egr1 elf1 esrra ets1 gata3 hnf4a mafk max mef2a myb nrf1 pax5 pou2f2 prdm1 sp1 srf tcf3 yy1\".split()\n",
    "tf_list = ['ctcf']\n",
    "for tf in tf_list:\n",
    "    results_path = '%s/Results/%s' % (BASE_DIR, tf)\n",
    "    \n",
    "    #make results path\n",
    "    mkdir_p(results_path)\n",
    "    \n",
    "    #Exract the available ChIP-seq list\n",
    "    chip_seq_list = glob.glob('%s/Data/Derived/%s/*' % (BASE_DIR, tf))\n",
    "    \n",
    "    #meme file with motifs to determine enrichment\n",
    "    test_meme_input = '%s/Data/Motifs/%s.meme' %(BASE_DIR, tf)\n",
    "    \n",
    "    #Run the cmplete pipeline\n",
    "    run_centrimo.run_centrimo(tf, chip_seq_list, test_meme_input, results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kipkurui/Project/Motif_Assessment/PAPER_Assessment_Data/Data/Motifs/ctcf.meme'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_meme_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Paper figures and tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above steps will only get up as far as obtaining the raw initial results. The steps that follow, outlines how the data was further processed and plotted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tf_list = \"cebpb ctcf egr1 elf1 esrra ets1 gata3 hnf4a mafk max mef2a myb nrf1 pax5 pou2f2 prdm1 sp1 srf tcf3 yy1\".split()\n",
    "results_path = '%s/Results/%s' % (BASE_DIR, tf)\n",
    "score_key = ['energy', 'gomer','sumlog', 'sumoc','maxoc', 'ama', 'maxlog']\n",
    "stat = 'auc'\n",
    "for tf in tf_list:\n",
    "    raw_data = []\n",
    "    raw_data.append([\"Motif\"])\n",
    "    flag = 0\n",
    "    for key in score_key:\n",
    "        i = 1\n",
    "        raw_data[0].append(key)\n",
    "        with open('%s/%s.%s' % (results_path,tf,key)) as score_out:\n",
    "            for line in score_out:\n",
    "                if line.split()[1]==\"AUC\":\n",
    "                    continue\n",
    "                else:\n",
    "                    if flag ==0:\n",
    "                        raw_data.append([line.split()[0]])\n",
    "                        raw_data[i].append(line.split()[1])\n",
    "                        i+=1\n",
    "                    else:\n",
    "                        raw_data[i].append(line.split()[1])\n",
    "                        i+=1\n",
    "            flag = 1\n",
    "        with open(\"%s/%s_%s.rawscores\" %(results_path,tf, stat), 'w') as raw_out:\n",
    "            for row in raw_data:\n",
    "                raw_out.writelines('\\t'.join(map(str, row)) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
