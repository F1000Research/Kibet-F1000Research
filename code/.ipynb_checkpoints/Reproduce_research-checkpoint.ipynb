{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Walk through all steps used in research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, lets import all the base modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import errno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Convert the ENCODE data into posneg format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "posneg format is a format we jsut made up to represent a file in the following format: \n",
    "\n",
    "    chromosome:start-end score sequence eg\n",
    "\n",
    "    chr19:10828427-10828527\t486.128011369018 TCTACTGGCACGTCTGCCTGCCAATAAGAT\n",
    "    \n",
    "To convert to this format, the following are required:\n",
    "\n",
    "1. A human genome file in Hg19 format that has been repeat-masked with NNs\n",
    "2. MEME fastafrombed script--jsut get compete meme tools, you'll need them later\n",
    "+ A bedwidden scrpt from the folowing site.\n",
    "\n",
    "A script to execute the whole process is provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Encode to bed file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cut -f1,2,3,7 ../Data/Downloaded/wgEncodeAwgTfbsBroadDnd41CtcfUniPk.narrowPeak >../Data/Derived/BroadDnd41Ctcf-tmp.bed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Extract the fasta files in the posneg format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#genome_path = 'provide path to hg19'\n",
    "genome_path = '/home/kipkurui/Project/MAT_server/Data/ChIP-seq/hg19.fa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system(\"./bed2chipseg.sh ../Data/Derived/BroadDnd41Ctcf-tmp.bed  ../Data/Derived/BroadDnd41Ctcf %s\" %genome_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming the motifs have been generated, they can be used to score the above sequences using the following scoring functions:\n",
    "\n",
    "    1. gomeroccupnacyscore\n",
    "    2. energyscore\n",
    "    3. maxoccupancyscore\n",
    "    4. occupancyscore\n",
    "    5. occupancyscore\n",
    "    6. sumlogoddsscore\n",
    "    7. maxlogoddsscore\n",
    "In my case, I querried a local motf database for motifs for a given TF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Import the module to directly access the functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import Assess_motifsdb as assess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Get the base directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath('Assess_motifsdb.py')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of this demo, we are going to use Ctcf motifs.\n",
    "\n",
    "Create a results directory complete with paths using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mkdir_p(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exc:\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
    "            pass\n",
    "        else:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf = 'ctcf'\n",
    "results_path = '%s/Results/%s' % (BASE_DIR, tf)\n",
    "mkdir_p(results_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the Results folder for Ctcf in place, the next this in to get a list of all the ChIP-seq data convered as shown above to posneg format. We use the function below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "chip_seq_list = glob.glob('%s/Data/Derived/%s/*' % (BASE_DIR, tf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use gomeroccupancy score for this demo, but a quick run for all the motifs can be run by looping though all the scoring functions as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for key in assess.score_extensions:\n",
    "    #assess.run_all(tf, key, '%s/Data/Motifs/%s.meme' %(BASE_DIR, tf), chip_seq_list, results_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the above cell for a quick run of all the scoring functions. Internally, the program chooses 10 random sequences, in a situation where more than 10 are available. We observed no better discrimination from more data, just takes lots of time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "key = 'gomeroccupancyscore'\n",
    "assess.run_all(tf, key, '%s/Data/Motifs/%s.meme' %(BASE_DIR, tf), chip_seq_list, results_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Combining the above steps to loop through multiple TFs and scoring functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tf_list = \"cebpb ctcf egr1 elf1 esrra ets1 gata3 hnf4a mafk max mef2a myb nrf1 pax5 pou2f2 prdm1 sp1 srf tcf3 yy1\".split()\n",
    "tf_list = ['ctcf']\n",
    "for tf in tf_list:\n",
    "    results_path = '%s/Results/%s' % (BASE_DIR, tf)\n",
    "    \n",
    "    #make results path\n",
    "    mkdir_p(results_path)\n",
    "    \n",
    "    #Exract the available ChIP-seq list\n",
    "    chip_seq_list = glob.glob('%s/Data/Derived/%s/*' % (BASE_DIR, tf))\n",
    "    \n",
    "    test_meme_input = '%s/Data/Motifs/%s.meme' %(BASE_DIR, tf)\n",
    "    \n",
    "    for key in assess.score_extensions:\n",
    "        assess.run_all(tf, key, test_meme_input, chip_seq_list, results_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##Run analysis using CentriMo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For motif enrichment analsys, a *run_centrimo* module is provided. This requires that the The MEME Suite tools version 4.10.0, which can be intsalled from <a href='http://meme-suite.org/doc/download.html?man_type=web'>MEME-Suite</a>.\n",
    "\n",
    "The steps followed are similar as above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import run_centrimo\n",
    "cebpb ctcf egr1 elf1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_list = \"esrra ets1 gata3 hnf4a mafk max mef2a myb nrf1 pax5 pou2f2 prdm1 sp1 srf tcf3 yy1\".split()\n",
    "#tf_list = ['sp1']\n",
    "for tf in tf_list:\n",
    "    results_path = '%s/Results/%s' % (BASE_DIR, tf)\n",
    "    \n",
    "    #make results path\n",
    "    mkdir_p(results_path)\n",
    "    \n",
    "    #Exract the available ChIP-seq list\n",
    "    chip_seq_list = glob.glob('%s/Data/Derived/%s/*' % (BASE_DIR, tf))\n",
    "    \n",
    "    #meme file with motifs to determine enrichment\n",
    "    test_meme_input = '%s/Data/Motifs/%s.meme' %(BASE_DIR, tf)\n",
    "    \n",
    "    #Run the cmplete pipeline\n",
    "    run_centrimo.run_centrimo(tf, chip_seq_list, test_meme_input, results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'esrra'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kipkurui/Project/Motif_Assessment/PAPER_Assessment_Data/Data/Motifs/ctcf.meme'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_meme_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Paper figures and tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above steps will only get up as far as obtaining the raw initial results. The steps that follow, outlines how the data was further processed and plotted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tf_list = \"cebpb ctcf egr1 elf1 esrra ets1 gata3 hnf4a mafk max mef2a myb nrf1 pax5 pou2f2 prdm1 sp1 srf tcf3 yy1\".split()\n",
    "results_path = '%s/Results/%s' % (BASE_DIR, tf)\n",
    "score_key = ['energy', 'gomer','sumlog', 'sumoc','maxoc', 'ama', 'maxlog']\n",
    "stat = 'auc'\n",
    "for tf in tf_list:\n",
    "    raw_data = []\n",
    "    raw_data.append([\"Motif\"])\n",
    "    flag = 0\n",
    "    for key in score_key:\n",
    "        i = 1\n",
    "        raw_data[0].append(key)\n",
    "        with open('%s/%s.%s' % (results_path,tf,key)) as score_out:\n",
    "            for line in score_out:\n",
    "                if line.split()[1]==\"AUC\":\n",
    "                    continue\n",
    "                else:\n",
    "                    if flag ==0:\n",
    "                        raw_data.append([line.split()[0]])\n",
    "                        raw_data[i].append(line.split()[1])\n",
    "                        i+=1\n",
    "                    else:\n",
    "                        raw_data[i].append(line.split()[1])\n",
    "                        i+=1\n",
    "            flag = 1\n",
    "        with open(\"%s/%s_%s.rawscores\" %(results_path,tf, stat), 'w') as raw_out:\n",
    "            for row in raw_data:\n",
    "                raw_out.writelines('\\t'.join(map(str, row)) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####MOTIF INFORMATION CONTENT AND LENGTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarize the motifs' information content, length as well as their scores. This is used to determine teh levle of correlation between the motif chracter and teh scores asigned. This helps understand how IC and motif length affect the score asigned by various scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "from __future__ import print_function\n",
    "import sys\n",
    "from math import log\n",
    "import os\n",
    "\n",
    "def mot_summary(motif_file, raw_scores, out_file):\n",
    "    '''\n",
    "    Summary of motif and score\n",
    "    '''\n",
    "    found = 0\n",
    "    row = 0\n",
    "    n_rows = 0\n",
    "    entropy = 0\n",
    "    total_entropy = 0\n",
    "    motifs = 0\n",
    "    name = \"\"\n",
    "    raw_dict = {}\n",
    "    with open(out_file, \"w\") as write_out:\n",
    "\n",
    "        with open(raw_scores) as raw_in:\n",
    "            for line in raw_in:\n",
    "                raw_dict[line.split()[0]] = line.split()[1:]\n",
    "        out = \"Motif_name\\tMotif_IC\\tAverage_IC\\tMotif_length\\t%s\\t%s\\t%s\\t%s\\n\" % \\\n",
    "              (raw_dict[\"Motif\"][0], raw_dict[\"Motif\"][1], raw_dict[\"Motif\"][2], raw_dict[\"Motif\"][3])\n",
    "\n",
    "        write_out.write(out)\n",
    "        with open(motif_file, \"r\") as motif_file:\n",
    "            for line in motif_file:\n",
    "                words = line.split()\n",
    "                if found == 0:\n",
    "                    if line.startswith(\"MOTIF\"):\n",
    "                        # allow for motifs without an alternative name\n",
    "                        if len(words) < 3:\n",
    "                            words.append(\"\")\n",
    "                        name = (words[1])\n",
    "                        found = 1\n",
    "                        motifs += motifs\n",
    "                        entropy = 0\n",
    "                        continue\n",
    "                if found == 1:\n",
    "                    if line.startswith(\"letter-probability\"):\n",
    "                        n_rows = int((line.split(\"w=\"))[1].split()[0])\n",
    "                        found = 2\n",
    "                    continue\n",
    "                if found == 2:\n",
    "                    if line == \"\\n\":\n",
    "                        continue\n",
    "                    else:\n",
    "                        check = 0\n",
    "                    for val in words:\n",
    "                        if float(val) > 0:\n",
    "                            check += float(val) * log(float(val))/log(2.0)\n",
    "                            entropy += float(val) * log(float(val))/log(2.0)\n",
    "                    row += 1\n",
    "                    if row >= n_rows:\n",
    "                        v = 2*n_rows+entropy\n",
    "                        out = '%s\\t%f\\t%f\\t%i\\t%f\\t%f\\t%f\\t%f\\n'\\\n",
    "                              % (name, v, (v/n_rows), n_rows, float(raw_dict[name][0]), float(raw_dict[name][1]),\n",
    "                                 float(raw_dict[name][2]), float(raw_dict[name][3]))\n",
    "                        write_out.write(out)\n",
    "                        #n+= 1\n",
    "                        #print(n)\n",
    "                        found = 0\n",
    "                        row = 0\n",
    "                        total_entropy += (v/n_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "statistics = ['auc','mncp']\n",
    "tf_list = \"cebpb ctcf egr1 elf1 esrra ets1 gata3 hnf4a mafk max mef2a myb nrf1 pax5 pou2f2 prdm1 sp1 srf tcf3 yy1\".split()\n",
    "for stat in statistics:\n",
    "    for tf in tf_list:\n",
    "        meme_file = '%s/Data/Motifs/%s.meme' %(BASE_DIR, tf)\n",
    "        results_path = '%s/Results/%s' % (BASE_DIR, tf)\n",
    "        test = mot_summary(meme_file,\"%s/%s_%s.rawscores\" % (results_path, tf, stat), \"%s/%s_%s_score_ic.txt\" % (results_path, tf, stat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
